{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL API INTEGRATION USING LLM MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import cloudinary\n",
    "import cloudinary.api\n",
    "import requests\n",
    "import os\n",
    "import gradio as gr\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import re\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Cloudinary Configuration\n",
    "cloudinary.config(\n",
    "    cloud_name='dopwnz1ze',\n",
    "    api_key='172931444248964',\n",
    "    api_secret='x6UFGqc1cSfBWcrTAGy7odv8duA'\n",
    ")\n",
    "\n",
    "# Predefined field names for document types\n",
    "FIELD_NAMES = {\n",
    "    \"Balance Sheet\": [\"Assets\", \"Liabilities\", \"Equity\", \"Current Assets\"],\n",
    "    \"Profit & Loss\": [\"Revenue\", \"Expenses\", \"Net Profit\", \"Operating Income\"],\n",
    "    \"Payslip\": [\"Employee Name\", \"Gross Salary\", \"Deductions\", \"Net Pay\", \"Bonus\"]\n",
    "}\n",
    "\n",
    "# Load GPT-2 model from Hugging Face\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "# Function to fetch available folders in Cloudinary\n",
    "def fetch_cloudinary_folders():\n",
    "    try:\n",
    "        response = cloudinary.api.root_folders()\n",
    "        folders = [folder['name'] for folder in response.get('folders', [])]\n",
    "        return folders\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching folders: {e}\")\n",
    "        return []\n",
    "\n",
    "def fetch_images_from_cloudinary(folder_name, num_images, save_local=True, local_dir=\"retrieved_images\"):\n",
    "    image_paths = []\n",
    "    next_cursor = None\n",
    "    retrieved_count = 0\n",
    "\n",
    "    # Ensure the local directory exists\n",
    "    if save_local and not os.path.exists(local_dir):\n",
    "        os.makedirs(local_dir)\n",
    "\n",
    "    while retrieved_count < num_images:\n",
    "        try:\n",
    "            response = cloudinary.api.resources(type=\"upload\", prefix=folder_name, max_results=min(100, num_images - retrieved_count), next_cursor=next_cursor)\n",
    "            images = response.get('resources', [])\n",
    "            next_cursor = response.get('next_cursor')\n",
    "\n",
    "            for image in images:\n",
    "                if retrieved_count >= num_images:\n",
    "                    break\n",
    "                image_url = image['secure_url']\n",
    "                img_data = requests.get(image_url).content\n",
    "\n",
    "                # Save the image to a temporary file and also save locally\n",
    "                with tempfile.NamedTemporaryFile(suffix=\".jpg\", delete=False) as tmpfile:\n",
    "                    tmpfile.write(img_data)\n",
    "                    image_paths.append(tmpfile.name)\n",
    "                    \n",
    "                    if save_local:\n",
    "                        # Save the image to the local directory\n",
    "                        local_image_path = os.path.join(local_dir, os.path.basename(tmpfile.name))\n",
    "                        with open(local_image_path, 'wb') as f:\n",
    "                            f.write(img_data)\n",
    "\n",
    "                retrieved_count += 1\n",
    "\n",
    "            if not next_cursor:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            return f\"Error retrieving images: {str(e)}\", []\n",
    "\n",
    "    return \"Images retrieved successfully!\", image_paths\n",
    "\n",
    "\n",
    "# Function to extract text from an image using OCR\n",
    "def extract_text_from_image(image):\n",
    "    text = pytesseract.image_to_string(image, config='--psm 6')\n",
    "    return text\n",
    "\n",
    "# Function to extract data based on predefined terms using regex\n",
    "def extract_data_using_regex(text, document_type):\n",
    "    extracted_data = {}\n",
    "    for term in FIELD_NAMES.get(document_type, []):\n",
    "        pattern = r\"\\b\" + re.escape(term) + r\"\\b.*?(\\d[\\d,\\.]*)\"\n",
    "        matches = re.search(pattern, text, flags=re.IGNORECASE)\n",
    "        extracted_data[term] = matches.group(1) if matches else \"null\"\n",
    "    return extracted_data\n",
    "\n",
    "# Function to extract data using GPT-2 (openai-community/gpt2)\n",
    "def extract_data_using_llm(text, document_type):\n",
    "    prompt = f\"\"\"\n",
    "    I have extracted the following text from a {document_type}. Please extract the following fields: {', '.join(FIELD_NAMES.get(document_type, []))}.\n",
    "    Text: {text}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add padding token if not already set\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token  # Use eos_token as padding token\n",
    "\n",
    "    # Encode the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    \n",
    "    # Generate the response from the model using max_new_tokens\n",
    "    output = model.generate(inputs[\"input_ids\"], max_new_tokens=200)\n",
    "    \n",
    "    # Decode the response\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract the fields from the decoded output\n",
    "    extracted_data = {}\n",
    "    lines = decoded_output.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        for term in FIELD_NAMES.get(document_type, []):\n",
    "            if term in line:\n",
    "                field_value = line.split(\":\")[-1].strip()\n",
    "                extracted_data[term] = field_value\n",
    "    return extracted_data\n",
    "\n",
    "# Function to clean values (remove commas, convert to float)\n",
    "def clean_values(values):\n",
    "    cleaned_values = []\n",
    "    for value in values:\n",
    "        value = value.replace(\",\", \"\")  # Remove commas\n",
    "        try:\n",
    "            cleaned_values.append(float(value))  # Try to convert to float\n",
    "        except ValueError:\n",
    "            cleaned_values.append(\"null\")  # If not a valid number, append 'null'\n",
    "    return cleaned_values\n",
    "\n",
    "# Function to save images as a ZIP file\n",
    "def save_images_as_zip(image_paths, zip_name=\"retrieved_images.zip\"):\n",
    "    zip_path = os.path.join(tempfile.gettempdir(), zip_name)\n",
    "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "        for img_path in image_paths:\n",
    "            arcname = os.path.basename(img_path)\n",
    "            zipf.write(img_path, arcname)\n",
    "    return zip_path\n",
    "\n",
    "# Function to extract, store in table format, and visualize\n",
    "def extract_and_visualize_from_cloudinary(folder_name, num_images, chart_type, document_type):\n",
    "    # Fetch images from the specified Cloudinary folder\n",
    "    status, image_paths = fetch_images_from_cloudinary(folder_name, int(num_images))\n",
    "    if \"Error\" in status:\n",
    "        return status, None, None, None, None, None\n",
    "\n",
    "    extracted_data = {field: [] for field in FIELD_NAMES.get(document_type, [])}\n",
    "    for img_path in image_paths:\n",
    "        try:\n",
    "            image = Image.open(img_path)\n",
    "            text = extract_text_from_image(image)\n",
    "            extracted_data_for_image = extract_data_using_regex(text, document_type)  # or extract_data_using_llm\n",
    "            for field, value in extracted_data_for_image.items():\n",
    "                extracted_data[field].append(value)\n",
    "        except Exception as e:\n",
    "            return f\"Error processing image: {str(e)}\", None, None, None, None, None\n",
    "\n",
    "    # Clean data for plotting and table representation\n",
    "    cleaned_data = {}\n",
    "    summed_data = {}\n",
    "    for field, values in extracted_data.items():\n",
    "        cleaned_values = clean_values(values)  # Now using clean_values\n",
    "        cleaned_data[field] = cleaned_values\n",
    "        summed_data[field] = sum([v for v in cleaned_values if isinstance(v, float)])\n",
    "\n",
    "    # Create a DataFrame for the main data table\n",
    "    max_length = max(len(v) for v in cleaned_data.values())\n",
    "    padded_data = {field: values + [\"\"] * (max_length - len(values)) for field, values in cleaned_data.items()}\n",
    "    df = pd.DataFrame(padded_data)\n",
    "\n",
    "    # Create a DataFrame for min and max values\n",
    "    min_max_data = {\n",
    "        \"Field\": [],\n",
    "        \"Highest Value\": [],\n",
    "        \"Lowest Value\": []\n",
    "    }\n",
    "    for field, values in cleaned_data.items():\n",
    "        numeric_values = [v for v in values if isinstance(v, float)]\n",
    "        min_max_data[\"Field\"].append(field)\n",
    "        min_max_data[\"Highest Value\"].append(max(numeric_values, default=\"null\"))\n",
    "        min_max_data[\"Lowest Value\"].append(min(numeric_values, default=\"null\"))\n",
    "\n",
    "    min_max_df = pd.DataFrame(min_max_data)\n",
    "\n",
    "    # Save DataFrames as temporary CSV files\n",
    "    main_csv_path = f\"{document_type.replace(' ', '_').lower()}_main.csv\"\n",
    "    min_max_csv_path = f\"{document_type.replace(' ', '_').lower()}_min_max.csv\"\n",
    "\n",
    "    df.to_csv(main_csv_path, index=False)\n",
    "    min_max_df.to_csv(min_max_csv_path, index=False)\n",
    "\n",
    "    # Save images as ZIP\n",
    "    zip_file_path = save_images_as_zip(image_paths)\n",
    "\n",
    "    # Visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    colors = plt.cm.tab20.colors\n",
    "\n",
    "    if chart_type == \"Bar Chart\":\n",
    "        ax.bar(summed_data.keys(), summed_data.values(), color=colors[:len(summed_data)])\n",
    "        ax.set_title(f\"{document_type} Data Visualization (Bar Chart)\")\n",
    "        ax.set_ylabel('Total Value')\n",
    "        ax.set_xlabel('Fields')\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "    elif chart_type == \"Pie Chart\":\n",
    "        ax.pie(\n",
    "            summed_data.values(),\n",
    "            labels=summed_data.keys(),\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=140,\n",
    "            colors=colors[:len(summed_data)]\n",
    "        )\n",
    "        ax.set_title(f\"{document_type} Data Visualization (Pie Chart)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the chart as a temporary image file\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".png\", delete=False) as tmpfile:\n",
    "        chart_path = tmpfile.name\n",
    "        plt.savefig(chart_path)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    return df.to_html(index=False), min_max_df.to_html(index=False), chart_path, main_csv_path, min_max_csv_path, zip_file_path\n",
    "\n",
    "# Gradio interface\n",
    "def create_gradio_interface():\n",
    "    cloudinary_folders = fetch_cloudinary_folders()\n",
    "\n",
    "    with gr.Blocks() as interface:\n",
    "        gr.Markdown(\"\"\" \n",
    "            <div style=\"text-align: center; font-size: 24px; font-weight: bold;\">\n",
    "                üå•Ô∏è Cloudinary Image OCR and Data Visualization üå•Ô∏è\n",
    "            </div>\n",
    "            <div style=\"text-align: center; font-size: 16px; color: gray;\">\n",
    "                Select your options below, and visualize extracted data efficiently.\n",
    "            </div>\n",
    "        \"\"\")\n",
    "\n",
    "        # Input Section\n",
    "        gr.Markdown(\"### Input Options\")\n",
    "        with gr.Row():\n",
    "            folder_name = gr.Dropdown(cloudinary_folders, label=\"Select Cloudinary Folder\", value=cloudinary_folders[0] if cloudinary_folders else None)\n",
    "            num_images = gr.Number(value=5, label=\"Number of Images to Fetch\", precision=0)\n",
    "            chart_type = gr.Dropdown(choices=[\"Bar Chart\", \"Pie Chart\"], value=\"Bar Chart\", label=\"Chart Type\")\n",
    "            document_type = gr.Dropdown(choices=[\"Balance Sheet\", \"Profit & Loss\", \"Payslip\"], value=\"Balance Sheet\", label=\"Document Type\")\n",
    "\n",
    "        # Output Section\n",
    "        gr.Markdown(\"### Output\")\n",
    "        with gr.Row():\n",
    "            data_table = gr.HTML(label=\"Extracted Data Table\")\n",
    "            min_max_table = gr.HTML(label=\"Min/Max Value Table\")\n",
    "            chart = gr.Image(label=\"Visualization Chart\", type=\"filepath\")\n",
    "\n",
    "        # Submit button functionality\n",
    "        submit_btn = gr.Button(\"Extract & Visualize\")\n",
    "        submit_btn.click(extract_and_visualize_from_cloudinary, inputs=[folder_name, num_images, chart_type, document_type], outputs=[data_table, min_max_table, chart])\n",
    "\n",
    "    return interface\n",
    "\n",
    "# Launch the Gradio interface\n",
    "if __name__ == \"__main__\":\n",
    "    create_gradio_interface().launch(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
