{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR TECHNIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PEDAL PEDAL OCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from paddleocr import PaddleOCR\n",
    "import cv2\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Initialize PaddleOCR with GPU support\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=True)  # Enable GPU\n",
    "\n",
    "SUPPORTED_FORMATS = ['jpg', 'jpeg', 'png']\n",
    "\n",
    "def process_images_with_paddleocr(input_folder, output_folder, width=800, height=600):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    processed_count = 0\n",
    "\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            ext = os.path.splitext(file)[1][1:].lower()\n",
    "            if ext in SUPPORTED_FORMATS:\n",
    "                image_path = os.path.join(root, file)\n",
    "                logging.info(f\"Processing image: {image_path}\")\n",
    "\n",
    "                try:\n",
    "                    # Read the image\n",
    "                    image = cv2.imread(image_path)\n",
    "\n",
    "                    # Convert to grayscale\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    # Resize the image\n",
    "                    image = cv2.resize(image, (width, height))\n",
    "\n",
    "                    # Perform OCR using PaddleOCR\n",
    "                    result = ocr.ocr(image, cls=True)\n",
    "\n",
    "                    # Filter result based on confidence threshold (> 0.8)\n",
    "                    text = '\\n'.join([line[1][0] for line in result[0] if line[1][1] > 0.8])\n",
    "\n",
    "                    # Save result\n",
    "                    relative_path = os.path.relpath(root, input_folder)\n",
    "                    local_folder = os.path.join(output_folder, relative_path)\n",
    "                    os.makedirs(local_folder, exist_ok=True)\n",
    "\n",
    "                    output_file = os.path.join(local_folder, f\"{os.path.splitext(file)[0]}.txt\")\n",
    "                    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(text)\n",
    "\n",
    "                    logging.info(f\"OCR result saved to: {output_file}\")\n",
    "                    processed_count += 1\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Failed to process image {image_path}. Error: {e}\")\n",
    "\n",
    "    logging.info(f\"OCR processing completed. Total images processed: {processed_count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_dir = r\"E:\\OCR BANK STATMENTS PROJECT\\VS CODE INFOSYS\\OCR BANK STATMENTS\\RETRIVED IMAGES\"\n",
    "    output_dir = r\"E:\\OCR BANK STATMENTS PROJECT\\VS CODE INFOSYS\\OCR BANK STATMENTS\\OCR OUTPUTS\\paddleocr\"\n",
    "    process_images_with_paddleocr(input_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESERACT OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "import cv2\n",
    "# Specify the path to the Tesseract executable (adjust based on your system)\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Input directory containing local images\n",
    "input_dir = r\"E:\\OCR BANK STATMENTS PROJECT\\VS CODE INFOSYS\\OCR BANK STATMENTS\\RETRIVED IMAGES\"\n",
    "# Output directory for OCR results\n",
    "output_dir = r\"E:\\OCR BANK STATMENTS PROJECT\\VS CODE INFOSYS\\OCR BANK STATMENTS\\OCR OUTPUTS\\teseract\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Supported image formats\n",
    "SUPPORTED_FORMATS = ['jpg', 'jpeg', 'png']\n",
    "\n",
    "# Process images for OCR using Tesseract\n",
    "def process_local_images(input_folder):\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            # Check for supported image formats\n",
    "            if file.split('.')[-1].lower() in SUPPORTED_FORMATS:\n",
    "                image_path = os.path.join(root, file)\n",
    "                print(f\"Processing image: {image_path}\")\n",
    "\n",
    "                # Perform OCR\n",
    "                try:\n",
    "                    # Read the image\n",
    "                    image = cv2.imread(image_path)\n",
    "\n",
    "                    # Convert image to grayscale for better OCR results\n",
    "                    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    # Perform OCR using Tesseract\n",
    "                    text = pytesseract.image_to_string(gray_image)\n",
    "\n",
    "                    # Create a mirrored folder structure locally for saving OCR results\n",
    "                    relative_path = os.path.relpath(root, input_folder)\n",
    "                    local_folder = os.path.join(output_dir, relative_path)\n",
    "                    os.makedirs(local_folder, exist_ok=True)\n",
    "\n",
    "                    # Save OCR result to a text file\n",
    "                    output_file = os.path.join(local_folder, f\"{file}.txt\")\n",
    "                    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(text)\n",
    "\n",
    "                    print(f\"OCR result saved to: {output_file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process image {image_path}. Error: {e}\")\n",
    "\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    process_local_images(input_dir)\n",
    "    print(\"OCR processing completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API INTEGRATION WITH CLOUDINARY FOR OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from paddleocr import PaddleOCR\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Function to process image, extract text using PaddleOCR or Tesseract, and save it to a file\n",
    "def extract_text_from_image(image, lang, ocr_engine):\n",
    "    try:\n",
    "        # Convert PIL Image to NumPy array\n",
    "        image_np = np.array(image)\n",
    "\n",
    "        # Convert image to RGB (both OCR engines expect RGB images)\n",
    "        image_rgb = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        text = \"\"\n",
    "        confidence_scores = []\n",
    "        lines = []\n",
    "        bounding_boxes = []\n",
    "\n",
    "        if ocr_engine == \"PaddleOCR\":\n",
    "            # Initialize PaddleOCR with the selected language\n",
    "            ocr = PaddleOCR(use_angle_cls=True, lang=lang, use_gpu=True)\n",
    "\n",
    "            # Perform OCR using PaddleOCR\n",
    "            result = ocr.ocr(image_rgb, cls=True)\n",
    "\n",
    "            # Extract text, confidence scores, and bounding boxes\n",
    "            for line in result[0]:\n",
    "                lines.append(line[1][0])  # Extracted text\n",
    "                confidence_scores.append(line[1][1])  # Confidence score\n",
    "                # Bounding box coordinates (x, y, width, height)\n",
    "                bbox = line[0]\n",
    "                bounding_boxes.append(bbox)\n",
    "                # Draw bounding box on the image\n",
    "                cv2.polylines(image_rgb, [np.array(bbox, dtype=np.int32)], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        elif ocr_engine == \"Tesseract\":\n",
    "            # Set Tesseract language\n",
    "            tesseract_lang = \"eng\" if lang == \"en\" else \"fra\"  # Adjust language codes for Tesseract\n",
    "            \n",
    "            # Perform OCR using Tesseract\n",
    "            data = pytesseract.image_to_data(image_rgb, lang=tesseract_lang, output_type=pytesseract.Output.DICT)\n",
    "\n",
    "            # Extract text, confidence scores, and bounding boxes\n",
    "            for i in range(len(data[\"text\"])):\n",
    "                if int(data[\"conf\"][i]) > 0:  # Ignore lines with confidence -1\n",
    "                    lines.append(data[\"text\"][i])\n",
    "                    confidence_scores.append(float(data[\"conf\"][i]))\n",
    "                    # Bounding box coordinates (x, y, width, height)\n",
    "                    x, y, w, h = data[\"left\"][i], data[\"top\"][i], data[\"width\"][i], data[\"height\"][i]\n",
    "                    bounding_boxes.append((x, y, x + w, y + h))\n",
    "                    # Draw bounding box on the image\n",
    "                    cv2.rectangle(image_rgb, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Combine text and confidence scores for the file\n",
    "        text_with_confidence = \"\\n\".join([f\"{line} (Confidence: {score:.2f})\" for line, score in zip(lines, confidence_scores)])\n",
    "\n",
    "        # Save the text and confidence scores to a file\n",
    "        output_file = \"extracted_text_with_confidence.txt\"\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text_with_confidence)\n",
    "\n",
    "        # Create a DataFrame for text and confidence\n",
    "        df = pd.DataFrame({\"Text\": lines, \"Confidence\": confidence_scores})\n",
    "        \n",
    "        # Convert image array back to PIL Image for display in Gradio\n",
    "        image_with_bboxes = Image.fromarray(image_rgb)\n",
    "        \n",
    "        # Return DataFrame, file path, and image with bounding boxes\n",
    "        return df, output_file, image_with_bboxes\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error processing image: {e}\"\n",
    "        error_file = \"error.txt\"\n",
    "        with open(error_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(error_message)\n",
    "        return error_message, pd.DataFrame(), error_file, None\n",
    "\n",
    "# Function to load a demo image\n",
    "def load_demo_image():\n",
    "    demo_image_path = \"E:/OCR BANK STATMENTS PROJECT/VS CODE INFOSYS/OCR BANK STATMENTS/RETRIVED IMAGES/BALANCE SHEET/BALANCE SHEET_avd5rnwfhfy4gewvukby.jpg\"  # Specify the path to the demo image file\n",
    "    demo_image = Image.open(demo_image_path)\n",
    "    return demo_image\n",
    "\n",
    "# Gradio Interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# OCR Tool Using multiple OCR Engines\")\n",
    "    gr.Markdown(\"Upload an image to extract text using PaddleOCR or Tesseract OCR.\")\n",
    "    \n",
    "    # Choose OCR engine options\n",
    "    with gr.Row():\n",
    "        ocr_engine = gr.Dropdown(label=\"Select OCR Engine\", choices=[\"PaddleOCR\", \"Tesseract\"], value=\"PaddleOCR\")\n",
    "\n",
    "    # Choose language options for OCR\n",
    "    with gr.Row():\n",
    "        ppocr_language = gr.Dropdown(label=\"Select Language\", choices=[\"en\", \"fr\"], value=\"en\")\n",
    "\n",
    "    # Choose picture upload options\n",
    "    with gr.Row():\n",
    "        upload_file = gr.Image(label=\"Upload Image\", type=\"pil\", interactive=True)  # Image component for uploading and taking pictures\n",
    "        demo_file = gr.Button(\"Use a Demo File\")\n",
    "\n",
    "    # DataFrame output for text and confidence\n",
    "    dataframe_output = gr.Dataframe(label=\"Text with Confidence Scores\", headers=[\"Text\", \"Confidence\"], interactive=False)\n",
    "    \n",
    "    # File output for downloading extracted text\n",
    "    file_output = gr.File(label=\"Download Extracted Text\")\n",
    "    \n",
    "    # Image output with bounding boxes\n",
    "    image_output = gr.Image(label=\"Processed Image with Bounding Boxes\", type=\"pil\")\n",
    "\n",
    "    # Process button\n",
    "    process_button = gr.Button(\"EXTRACT TEXT\")\n",
    "    \n",
    "    # Button to trigger OCR\n",
    "    process_button.click(\n",
    "        fn=extract_text_from_image,\n",
    "        inputs=[upload_file, ppocr_language, ocr_engine],\n",
    "        outputs=[dataframe_output, file_output, image_output]\n",
    "    )\n",
    "\n",
    "    # Button to trigger \"Use a Demo File\"\n",
    "    demo_file.click(\n",
    "        fn=load_demo_image,\n",
    "        outputs=[upload_file]  # This will set the demo image as the uploaded file\n",
    "    )\n",
    "\n",
    "# Run the Gradio app\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
